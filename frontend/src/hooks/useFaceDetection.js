import { useEffect, useRef, useState } from 'react';
import * as faceDetection from '@tensorflow-models/face-detection';
import '@tensorflow/tfjs-backend-webgl';

// ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ•ãƒ©ã‚°ï¼ˆReact StrictModeå¯¾å¿œï¼‰
let globalFaceDetectionInitialized = false;

// TensorFlow.js Face Detection ã®è¨­å®š
const DETECTION_CONFIG = {
	// åˆæ„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
	confidence: 0.5,           // ç¢ºä¿¡åº¦é–¾å€¤ï¼ˆç·©å’Œï¼‰
	sizeThresholdOn: 0.12,     // é¡”ã‚µã‚¤ã‚ºé–¾å€¤ï¼ˆçŸ­è¾ºæ¯”ï¼‰ONï¼ˆç·©å’Œï¼‰
	sizeThresholdOff: 0.03,    // é¡”ã‚µã‚¤ã‚ºé–¾å€¤ï¼ˆçŸ­è¾ºæ¯”ï¼‰OFFï¼ˆç·©å’Œï¼‰
	appearDuration: 300,       // å‡ºç¾ç¶™ç¶šæ™‚é–“ï¼ˆmsï¼‰ï¼ˆçŸ­ç¸®ï¼‰
	smoothingFrames: 3         // ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ï¼ˆçŸ­ç¸®ï¼‰
};

export function useFaceDetection(videoRef, canvasRef, isActive) {
	const [currentCount, setCurrentCount] = useState(0);
	const [isDetecting, setIsDetecting] = useState(false);
	const [faceDetectionDebugInfo, setFaceDetectionDebugInfo] = useState({
		status: 'initializing',
		initializationStep: 'loading_scripts',
		lastDetection: null,
		detectionCount: 0,
		error: null
	});
	
	// æ–°ã—ã„çŠ¶æ…‹ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ï¼ˆç°¡ç´ åŒ–ï¼‰
	const [detectionState, setDetectionState] = useState({
		phase: 'idle',           // 'idle', 'detecting', 'counted'
		startTime: 0,           // æ¤œå‡ºé–‹å§‹æ™‚åˆ»
		lastCountTime: 0        // æœ€å¾Œã®ã‚«ã‚¦ãƒ³ãƒˆæ™‚åˆ»ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
	});
	
	// ãƒ‡ãƒãƒƒã‚°ç”¨ã®çŠ¶æ…‹ãƒ­ã‚°
	useEffect(() => {
		console.log('ğŸ” æ¤œå‡ºçŠ¶æ…‹å¤‰æ›´:', detectionState);
	}, [detectionState]);
	
	const faceDetectionRef = useRef(null);
	const lastDetectionRef = useRef(null);
	const smoothingBufferRef = useRef([]);
	const detectionIntervalRef = useRef(null);


	// TensorFlow.js Face Detection ã®åˆæœŸåŒ–
	useEffect(() => {
		async function initFaceDetection() {
			// é‡è¤‡å®Ÿè¡Œã‚’é˜²æ­¢ï¼ˆã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ•ãƒ©ã‚°ä½¿ç”¨ï¼‰
			if (globalFaceDetectionInitialized) {
				console.log('TensorFlow.jsåˆæœŸåŒ–ã¯æ—¢ã«å®Ÿè¡Œæ¸ˆã¿ã§ã™ï¼ˆã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ•ãƒ©ã‚°ï¼‰');
				return;
			}
			
			console.log('TensorFlow.jsåˆæœŸåŒ–ã‚’é–‹å§‹ã—ã¾ã™ï¼ˆã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ•ãƒ©ã‚°ï¼‰');
			globalFaceDetectionInitialized = true;
			
			try {
				console.log('TensorFlow.jsåˆæœŸåŒ–é–‹å§‹');
				setFaceDetectionDebugInfo(prev => ({ 
					...prev, 
					status: 'initializing',
					initializationStep: 'loading_model',
					error: null
				}));
				
				// TensorFlow.js Face Detection ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿
				console.log('TensorFlow.js Face Detectionãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­...');
				
				// åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’ç¢ºèª
				console.log('åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«:', faceDetection.SupportedModels);
				
				// MediaPipeFaceDetectorã‚’ä½¿ç”¨ï¼ˆæ­£ã—ã„è¨­å®šï¼‰
				const detectorConfig = {
					runtime: 'mediapipe', // 'tfjs'ã§ã¯ãªã'mediapipe'ã‚’ä½¿ç”¨
					solutionPath: 'https://cdn.jsdelivr.net/npm/@mediapipe/face_detection',
					modelType: 'short',
					maxFaces: 1
				};
				
				console.log('Detectorè¨­å®š:', detectorConfig);
				
				faceDetectionRef.current = await faceDetection.createDetector(
					faceDetection.SupportedModels.MediaPipeFaceDetector,
					detectorConfig
				);
				
				console.log('Detectorä½œæˆå®Œäº†:', {
					detector: faceDetectionRef.current,
					detectorMethods: Object.getOwnPropertyNames(Object.getPrototypeOf(faceDetectionRef.current))
				});
				
				console.log('TensorFlow.js Face Detectionãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†');
				setFaceDetectionDebugInfo(prev => ({ 
					...prev, 
					status: 'ready',
					initializationStep: 'completed'
				}));
				
			} catch (error) {
				console.error('TensorFlow.jsåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼:', error);
				console.error('ã‚¨ãƒ©ãƒ¼ã®è©³ç´°:', {
					name: error.name,
					message: error.message,
					stack: error.stack
				});
				
				setFaceDetectionDebugInfo(prev => ({ 
					...prev, 
					status: 'error',
					error: `${error.name}: ${error.message}`
				}));
				
				// ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ã‚’è©¦è¡Œ
				initFallbackFaceDetection();
			}
		}
		
		// ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ï¼ˆç°¡æ˜“çš„ãªé¡”æ¤œå‡ºï¼‰
		function initFallbackFaceDetection() {
			console.log('ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯é¡”æ¤œå‡ºã‚’åˆæœŸåŒ–ã—ã¾ã™');
			setFaceDetectionDebugInfo(prev => ({ 
				...prev, 
				status: 'fallback',
				initializationStep: 'fallback_mode',
				error: 'TensorFlow.jsåˆæœŸåŒ–å¤±æ•—ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã‚’ä½¿ç”¨'
			}));
			
			// ç°¡æ˜“çš„ãªé¡”æ¤œå‡ºãƒ­ã‚¸ãƒƒã‚¯ï¼ˆå®Ÿéš›ã®é¡”æ¤œå‡ºã¯è¡Œã‚ãªã„ãŒã€ã‚·ã‚¹ãƒ†ãƒ ã¯å‹•ä½œã™ã‚‹ï¼‰
			faceDetectionRef.current = {
				estimateFaces: async (video, options) => {
					// ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã§ã¯ç©ºã®é…åˆ—ã‚’è¿”ã™
					console.log('ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰: ç©ºã®æ¤œå‡ºçµæœã‚’è¿”ã™');
					return [];
				},
				send: (data) => {
					// ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã§ã¯ä½•ã‚‚ã—ãªã„
					console.log('ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰: æ¤œå‡ºè¦æ±‚ã‚’ç„¡è¦–');
				},
				onResults: (callback) => {
					// ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã§ã¯ä½•ã‚‚ã—ãªã„
					console.log('ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰: çµæœã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’è¨­å®š');
				},
				setOptions: (options) => {
					// ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã§ã¯ä½•ã‚‚ã—ãªã„
					console.log('ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰: ã‚ªãƒ—ã‚·ãƒ§ãƒ³è¨­å®šã‚’ç„¡è¦–', options);
				}
			};
			
			// ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã§ã‚‚æ¤œå‡ºçŠ¶æ…‹ã‚’æ›´æ–°
			setFaceDetectionDebugInfo(prev => ({ 
				...prev, 
				status: 'fallback_ready',
				initializationStep: 'fallback_completed'
			}));
		}
		
		
		initFaceDetection();
		
		// ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—é–¢æ•°
		return () => {
			// ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ•ãƒ©ã‚°ã¯ãƒªã‚»ãƒƒãƒˆã—ãªã„ï¼ˆReact StrictModeå¯¾å¿œï¼‰
		};
	}, []); // ä¾å­˜é…åˆ—ã¯ç©ºã®ã¾ã¾ï¼ˆä¸€åº¦ã ã‘å®Ÿè¡Œï¼‰

	// æ¤œå‡ºçµæœã®å‡¦ç†ï¼ˆTensorFlow.jsç”¨ï¼‰
	async function handleDetectionResults() {
		if (!isActive || !canvasRef.current || !videoRef.current || !faceDetectionRef.current) return;
		
		try {
			const canvas = canvasRef.current;
			const video = videoRef.current;
			const ctx = canvas.getContext('2d');
			
			// ã‚­ãƒ£ãƒ³ãƒã‚¹ã‚µã‚¤ã‚ºã‚’ãƒ“ãƒ‡ã‚ªã«åˆã‚ã›ã‚‹
			canvas.width = video.videoWidth;
			canvas.height = video.videoHeight;
			
			// å‰ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚¯ãƒªã‚¢
			ctx.clearRect(0, 0, canvas.width, canvas.height);
			
			// TensorFlow.jsã§é¡”æ¤œå‡ºã‚’å®Ÿè¡Œ
			const faces = await faceDetectionRef.current.estimateFaces(video, {
				flipHorizontal: false,
				returnTensors: false
			});
			
			// ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’æ›´æ–°
			setFaceDetectionDebugInfo(prev => ({
				...prev,
				detectionCount: prev.detectionCount + 1,
				lastDetection: faces ? faces.length : 0
			}));
			
			if (faces && faces.length > 0) {
				const face = faces[0]; // æœ€åˆã®æ¤œå‡ºçµæœã‚’ä½¿ç”¨
				
				const bbox = face.box;
				
				// TensorFlow.jsã®bboxæ§‹é€ ã‚’ç¢ºèªã—ã¦é©åˆ‡ã«å‡¦ç†
				let x, y, width, height;
				
				// è¤‡æ•°ã®bboxæ§‹é€ ã«å¯¾å¿œ
				if (bbox.x !== undefined && bbox.y !== undefined && bbox.width !== undefined && bbox.height !== undefined) {
					// æ¨™æº–çš„ãª {x, y, width, height} å½¢å¼
					x = bbox.x;
					y = bbox.y;
					width = bbox.width;
					height = bbox.height;
				} else if (bbox.xCenter !== undefined && bbox.yCenter !== undefined && bbox.width !== undefined && bbox.height !== undefined) {
					// MediaPipeå½¢å¼ {xCenter, yCenter, width, height}
					x = bbox.xCenter - bbox.width / 2;
					y = bbox.yCenter - bbox.height / 2;
					width = bbox.width;
					height = bbox.height;
				} else if (bbox.left !== undefined && bbox.top !== undefined && bbox.right !== undefined && bbox.bottom !== undefined) {
					// {left, top, right, bottom} å½¢å¼
					x = bbox.left;
					y = bbox.top;
					width = bbox.right - bbox.left;
					height = bbox.bottom - bbox.top;
				} else if (bbox.xMin !== undefined && bbox.xMax !== undefined && bbox.yMin !== undefined && bbox.yMax !== undefined) {
					// {xMin, xMax, yMin, yMax} å½¢å¼ï¼ˆTensorFlow.js MediaPipeFaceDetectorï¼‰
					
					// MediaPipeFaceDetectorã¯ç›¸å¯¾åº§æ¨™ï¼ˆ0-1ã®ç¯„å›²ï¼‰ã‚’ä½¿ç”¨
					// ãŸã ã—ã€åº§æ¨™å€¤ãŒ0ã®å ´åˆã¯åˆ¥ã®å‡¦ç†ãŒå¿…è¦
					if (bbox.xMin === 0 && bbox.xMax === 0 && bbox.yMin === 0 && bbox.yMax === 0) {
						// keypointsã‹ã‚‰åº§æ¨™ã‚’æ¨å®š
						if (face.keypoints && face.keypoints.length > 0) {
							const keypoints = face.keypoints;
							const xCoords = keypoints.map(kp => kp.x);
							const yCoords = keypoints.map(kp => kp.y);
							const minX = Math.min(...xCoords);
							const maxX = Math.max(...xCoords);
							const minY = Math.min(...yCoords);
							const maxY = Math.max(...yCoords);
							
							x = minX;
							y = minY;
							width = maxX - minX;
							height = maxY - minY;
						} else {
							return;
						}
					} else {
						// MediaPipeFaceDetectorã¯æ—¢ã«çµ¶å¯¾åº§æ¨™ï¼ˆãƒ”ã‚¯ã‚»ãƒ«å€¤ï¼‰ã‚’è¿”ã™
						x = bbox.xMin;
						y = bbox.yMin;
						width = bbox.xMax - bbox.xMin;
						height = bbox.yMax - bbox.yMin;
					}
				} else {
					console.error('æœªçŸ¥ã®bboxæ§‹é€ :', bbox);
					return;
				}
				
				// åº§æ¨™å€¤ãŒ0ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
				if (width === 0 || height === 0) {
					return;
				}
				
				// é¡”ã®ã‚µã‚¤ã‚ºã‚’è¨ˆç®—ï¼ˆçŸ­è¾ºæ¯”ï¼‰
				const faceSize = Math.min(width, height);
				const shortSide = Math.min(video.videoWidth, video.videoHeight);
				const sizeRatio = faceSize / shortSide;
				
				// ã‚µã‚¤ã‚ºè¨ˆç®—ï¼ˆãƒ­ã‚°å‰Šé™¤ï¼‰
				
							// ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ï¼ˆä¸­å¤®å€¤ï¼‰
			smoothingBufferRef.current.push(sizeRatio);
			if (smoothingBufferRef.current.length > DETECTION_CONFIG.smoothingFrames) {
				smoothingBufferRef.current.shift();
			}
			
			// ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ãƒãƒƒãƒ•ã‚¡ãŒç©ºã®å ´åˆã¯ç¾åœ¨ã®å€¤ã‚’ãã®ã¾ã¾ä½¿ç”¨
			const smoothedSize = smoothingBufferRef.current.length > 0 
				? getMedian(smoothingBufferRef.current) 
				: sizeRatio;
				const now = Date.now();
				
				// ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°çµæœï¼ˆãƒ­ã‚°å‰Šé™¤ï¼‰
				
							// æ–°ã—ã„ã‚«ã‚¦ãƒ³ãƒˆãƒ­ã‚¸ãƒƒã‚¯ï¼ˆä¿®æ­£ç‰ˆï¼‰
			if (smoothedSize >= DETECTION_CONFIG.sizeThresholdOn) {
				// çŠ¶æ…‹é·ç§»ã®å‡¦ç†ï¼ˆä¿®æ­£ç‰ˆï¼‰
				if (detectionState.phase === 'idle') {
					// idle â†’ detectingï¼ˆæ¤œå‡ºé–‹å§‹ï¼‰
					setDetectionState(prev => ({
						...prev,
						phase: 'detecting',
						startTime: now
					}));
					console.log('ğŸ”„ çŠ¶æ…‹é·ç§»: idle â†’ detecting', {
						smoothedSize,
						threshold: DETECTION_CONFIG.sizeThresholdOn,
						timestamp: now
					});
					
					// é¡”æ ã‚’æç”»
					drawFaceBox(ctx, {x, y, width, height}, 'detecting');
				} else if (detectionState.phase === 'detecting') {
					// detectingçŠ¶æ…‹ã§ã¯é¡”æ¤œå‡ºã‚’ç¶™ç¶šã—ã€ã‚¿ã‚¤ãƒãƒ¼ã§ãƒã‚§ãƒƒã‚¯
					const elapsed = now - detectionState.startTime;
					if (elapsed >= DETECTION_CONFIG.appearDuration) {
						// ã‚«ã‚¦ãƒ³ãƒˆå®Ÿè¡Œ
						setCurrentCount(prev => {
							const newCount = prev + 1;
							console.log('ğŸ¯ ã‚«ã‚¦ãƒ³ãƒˆã‚’å¢—åŠ :', newCount);
							return newCount;
						});
						
						setDetectionState(prev => ({
							...prev,
							phase: 'counted',
							lastCountTime: now
						}));
						console.log('âœ… çŠ¶æ…‹é·ç§»: detecting â†’ counted');
					}
					
					// detectingçŠ¶æ…‹ã§ã‚‚é¡”æ ã‚’æç”»ï¼ˆç¶™ç¶šè¡¨ç¤ºï¼‰
					drawFaceBox(ctx, {x, y, width, height}, 'detecting');
				} else if (detectionState.phase === 'counted') {
					// countedçŠ¶æ…‹ã§ã¯é¡”æ¤œå‡ºã‚’ç¶™ç¶šã—ã€é¡”ãŒéš ã‚Œã‚‹ã¾ã§å¾…æ©Ÿ
					// è‡ªå‹•ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã¯å‰Šé™¤ï¼ˆé¡”ãŒæ¤œå‡ºã•ã‚Œãªã„æ™‚ã®ã¿idleã«é·ç§»ï¼‰
					
					// é¡”æ ã‚’æç”»ï¼ˆç¢ºå®šçŠ¶æ…‹ï¼‰
					drawFaceBox(ctx, {x, y, width, height}, 'confirmed');
				}
				
			} else if (smoothedSize < DETECTION_CONFIG.sizeThresholdOff) {
				// é¡”ãŒéš ã‚ŒãŸå ´åˆã¯idleçŠ¶æ…‹ã«æˆ»ã‚‹ï¼ˆå…¨çŠ¶æ…‹ã‹ã‚‰ï¼‰
				// ãŸã ã—ã€countedçŠ¶æ…‹ã®å ´åˆã¯å°‘ã—é…å»¶ã‚’å…¥ã‚Œã‚‹
				if (detectionState.phase !== 'idle') {
					if (detectionState.phase === 'counted') {
						// countedçŠ¶æ…‹ã®å ´åˆã¯å°‘ã—å¾…æ©Ÿã—ã¦ã‹ã‚‰idleã«æˆ»ã‚‹
						setTimeout(() => {
							setDetectionState(prev => ({
								...prev,
								phase: 'idle',
								startTime: 0
							}));
							console.log('ğŸ‘¤ çŠ¶æ…‹é·ç§»: counted â†’ idleï¼ˆé…å»¶å¾Œï¼‰', {
								smoothedSize,
								threshold: DETECTION_CONFIG.sizeThresholdOff,
								timestamp: Date.now()
							});
						}, 200); // 200msé…å»¶
					} else {
						setDetectionState(prev => ({
							...prev,
							phase: 'idle',
							startTime: 0
						}));
						console.log('ğŸ‘¤ çŠ¶æ…‹é·ç§»: ä»»æ„ã®çŠ¶æ…‹ â†’ idleï¼ˆé¡”ãŒéš ã‚ŒãŸï¼‰', {
							previousPhase: detectionState.phase,
							smoothedSize,
							threshold: DETECTION_CONFIG.sizeThresholdOff,
							timestamp: now
						});
					}
				}
			} else {
				// é–¾å€¤ã®ç¯„å›²å†…ã§ã‚‚æç”»ã¯è¡Œã†
				drawFaceBox(ctx, {x, y, width, height}, 'detecting');
			}
			} else {
				// é¡”ãŒæ¤œå‡ºã•ã‚Œãªã„å ´åˆï¼ˆfaces.length === 0ï¼‰
				const now = Date.now();
				if (detectionState.phase !== 'idle') {
					setDetectionState(prev => ({
						...prev,
						phase: 'idle',
						startTime: 0
					}));
					console.log('ğŸ‘¤ çŠ¶æ…‹é·ç§»: ä»»æ„ã®çŠ¶æ…‹ â†’ idleï¼ˆé¡”ãŒæ¤œå‡ºã•ã‚Œãªã„ï¼‰', {
						previousPhase: detectionState.phase,
						facesCount: faces ? faces.length : 0,
						timestamp: now
					});
				}
			}
		} catch (error) {
			console.error('æ¤œå‡ºçµæœå‡¦ç†ã‚¨ãƒ©ãƒ¼:', error);
			setFaceDetectionDebugInfo(prev => ({
				...prev,
				error: `æ¤œå‡ºçµæœå‡¦ç†ã‚¨ãƒ©ãƒ¼: ${error.message}`
			}));
		}
	}

	// é¡”æ ã®æç”»ï¼ˆTensorFlow.jsç”¨ï¼‰
	function drawFaceBox(ctx, bbox, state) {
		// TensorFlow.jsã®bboxã¯ {x, y, width, height} å½¢å¼
		const x = bbox.x;
		const y = bbox.y;
		const width = bbox.width;
		const height = bbox.height;
		
		// æç”»ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆãƒ­ã‚°å‰Šé™¤ï¼‰
		
		ctx.strokeStyle = state === 'confirmed' ? '#10b981' : '#f59e0b';
		ctx.lineWidth = 3;
		ctx.strokeRect(x, y, width, height);
		
		// é¡”æ ã‚’æç”»ï¼ˆãƒ­ã‚°å‰Šé™¤ï¼‰
	}

	// ä¸­å¤®å€¤è¨ˆç®—ï¼ˆå®‰å…¨ç‰ˆï¼‰
	function getMedian(arr) {
		if (!arr || arr.length === 0) return 0;
		const sorted = [...arr].sort((a, b) => a - b);
		const mid = Math.floor(sorted.length / 2);
		return sorted.length % 2 === 0 ? (sorted[mid - 1] + sorted[mid]) / 2 : sorted[mid];
	}

	// æ¤œå‡ºã®é–‹å§‹/åœæ­¢
	useEffect(() => {
		if (!faceDetectionRef.current || !videoRef.current) return;
		
		if (isActive) {
			// æ¤œå‡ºé–‹å§‹
			setIsDetecting(true);
		} else {
			setIsDetecting(false);
			setDetectionState(prev => ({
				...prev,
				phase: 'idle',
				startTime: 0
			}));
		}
	}, [isActive]);

	// ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã®æ¤œå‡ºå®Ÿè¡Œï¼ˆçŠ¶æ…‹ã«å¿œã˜ãŸé »åº¦åˆ¶å¾¡ï¼‰
	useEffect(() => {
		if (!isActive || !faceDetectionRef.current || !videoRef.current) return;
		
		const video = videoRef.current;
		
		// æ¤œå‡ºé »åº¦ã‚’çŠ¶æ…‹ã«å¿œã˜ã¦åˆ¶å¾¡
		const getDetectionInterval = () => {
			// ã™ã¹ã¦ã®çŠ¶æ…‹ã§åŒã˜é »åº¦ã‚’ä½¿ç”¨ï¼ˆ20FPSï¼‰
			return 1000 / 20; // 20FPS (50ms)
		};
		
		const startDetection = () => {
			if (detectionIntervalRef.current) {
				clearInterval(detectionIntervalRef.current);
			}
			
			const interval = setInterval(async () => {
				if (video.readyState === video.HAVE_ENOUGH_DATA) {
					try {
						await handleDetectionResults();
					} catch (error) {
						console.error('é¡”æ¤œå‡ºå®Ÿè¡Œã‚¨ãƒ©ãƒ¼:', error);
						setFaceDetectionDebugInfo(prev => ({
							...prev,
							error: error.message
						}));
					}
				}
			}, getDetectionInterval());
			
			detectionIntervalRef.current = interval;
		};
		
		startDetection();
		
		return () => {
			if (detectionIntervalRef.current) {
				clearInterval(detectionIntervalRef.current);
			}
		};
	}, [isActive, detectionState.phase]); // detectionState.phaseã‚’ä¾å­˜é…åˆ—ã«è¿½åŠ 

	return {
		currentCount,
		isDetecting,
		detectionState,
		faceDetectionDebugInfo,
		resetCount: () => setCurrentCount(0)
	};
}
